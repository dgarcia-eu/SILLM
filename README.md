# The Social Informatics of Large Language Models
[David Garcia](http://dgarcia.eu) and [Indira Sen](https://indiiigo.github.io/), 2023

This course will cover the latest research on generative pre-trained large-language models (LLMs) from a social informatics approach. It will be centered around readings and practical exercises to understand the design and training of the models and to be able to actively use them in a Python programming environment. The course will cover current methods to quantify behavioral patterns in generative LLM, apply them for social scientific tasks, such as zero-shot or few-shot classification of text, and inform further social science research. The course will cover the current and potential future role of generative LLMs in society and how biases and representation issues affect the training and design of generative LLMs.



# Learning objectives

Upon completion of this course, students will be able to:
- Critically reflect on the validity, stability, and accuracy of large language models and their role in society
- Systematically use large language models as software tools integrated with their own code
- Design social and behavioral science tasks for large language models to perform and evaluate their performance and reliability
- Audit the behavior of large language models to detect inconsistencies and other issues when compared to human behavior
    
    
# Course assessment

The course assessment will be based on a final project (60%) and on grades of assignments (40%). A 10% bonus can be achieved with class participation. To be eligible for the project, students must hand in their solutions for the assignments and get a passing aggregate grade on the assignments (60/100).



# Assignments
The course has four assignments, with approximately five weeks per assignment. There is one deadline to submit the solutions of the first two assignments (Dec 6) and a second deadline for the solutions of the last two assignments (Jan 31). 


# Course topics
- [Introduction and Motivation](https://dgarcia-eu.github.io/SILLM/Slides/01_Intro/Slides.html)
- [What does large mean?](https://dgarcia-eu.github.io/SILLM/Slides/02_MeaningOfLarge/Slides.html)
  - Reading 1: [Reconciling modern machine-learning practice and the classical biasâ€“variance trade-off](https://www.pnas.org/doi/10.1073/pnas.1903070116)
  - Reading 2: [One Parameter is Always Enough](http://colala.berkeley.edu/papers/piantadosi2018one.pdf)
- [Natural Language Processing basics](https://github.com/dgarcia-eu/SILLM/blob/main/Slides/03_nlp_basics_1.pdf)
- [Advanced concepts in Natural Language Processing](https://github.com/dgarcia-eu/SILLM/blob/main/Slides/04_nlp_intermediate.pdf.pdf)
- [Artificial General Intelligence and applications of LLMs](https://github.com/dgarcia-eu/SILLM/blob/main/Slides/05_NLP_and_AGI.pdf)
  - Reading: [Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)
- [Content analysis with generative LLM](https://github.com/dgarcia-eu/SILLM/blob/main/Slides/06_content_labeling.pdf.pdf)
  - Reading 1: [ChatGPT outperforms crowd workers for text-annotation tasks](https://www.pnas.org/doi/10.1073/pnas.2305016120)
  - Reading 2: [Chatbots Are Not Reliable Text Annotators](https://arxiv.org/abs/2311.05769)
- Social simulacra and generative agents
  - Reading 1: [Social Simulacra: Creating Populated Prototypes for Social Computing Systems](https://arxiv.org/pdf/2208.04024.pdf)
  - Reading 2: [Simulating social media using large language models to evaluate alternative news feed algorithms](https://arxiv.org/pdf/2310.05984.pdf)
- [Prompt engineering](https://dgarcia-eu.github.io/SILLM/Slides/08_PromptEngineering/Slides.html)
  - Reading 1: [Large Language Models Understand and Can Be Enhanced by
Emotional Stimuli](https://arxiv.org/pdf/2307.11760.pdf)
  - Reading 2: [Evaluating and Mitigating Discrimination in Language Model Decisions](https://arxiv.org/pdf/2312.03689.pdf)
  - Additionally: [OpenAI prompt engineering manual](https://platform.openai.com/docs/guides/prompt-engineering)
- [Psychometrics of LLMs and LLM Behavior](https://github.com/dgarcia-eu/SILLM/blob/main/Slides/09_bias_psychometrics_experiments.pdf.pdf):
  - Reading 1: [AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories](https://journals.sagepub.com/doi/full/10.1177/17456916231214460)
  - Reading 2: [Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies](https://proceedings.mlr.press/v202/aher23a.html)
- Impact of LLMs in society:
  - Reading 1: [US eating disorder helpline takes down AI chatbot over harmful advice](https://www.theguardian.com/technology/2023/may/31/eating-disorder-hotline-union-ai-chatbot-harm)
  - Reading 2: [Are large language models a threat to digital public goods? evidence from activity on stack overflow](https://arxiv.org/abs/2307.07367)
- Critique and ethics of LLMs:
  - Reading 1: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/10.1145/3442188.3445922)
  - Reading 2: [ChatGPT Is a Blurry JPEG of the Web](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)
- Course summary and preliminary project presentations
